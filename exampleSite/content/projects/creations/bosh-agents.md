{
  "title": "Batch and Stream processing for dataset from the US Department of Transportation",
  "date": "",
  "image": "",
  "link": "https://github.com/",
  "description": "Extracted and cleaned the dataset, and stored around 0.3 billion records into HDFS in a cluster built by Amazon EMR.",
  "tags": ["AWS","HDFS","Dynamodb","Spark","Kafka"],
  "fact": "",
  "featured":true
}
